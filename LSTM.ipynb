{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWUmkg3yG0Nlr4Lkxp4J6i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdwSanA/DPro_Tareas/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH6NUbpgiDFU",
        "outputId": "ca8278b9-4913-437e-eaa4-190401f4d5ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading IMDb dataset...\n",
            "Train shape: (25000, 80), Test shape: (25000, 80)\n",
            "\n",
            "=== Training SimpleRNN ===\n",
            "Epoch 1/5\n",
            "782/782 - 56s - 71ms/step - accuracy: 0.5458 - loss: 0.6845 - val_accuracy: 0.6040 - val_loss: 0.6444\n",
            "Epoch 2/5\n",
            "782/782 - 50s - 63ms/step - accuracy: 0.6764 - loss: 0.5928 - val_accuracy: 0.6813 - val_loss: 0.5806\n",
            "Epoch 3/5\n",
            "782/782 - 82s - 105ms/step - accuracy: 0.7590 - loss: 0.4928 - val_accuracy: 0.7305 - val_loss: 0.5490\n",
            "Epoch 4/5\n",
            "782/782 - 50s - 63ms/step - accuracy: 0.7832 - loss: 0.4599 - val_accuracy: 0.7756 - val_loss: 0.5033\n",
            "Epoch 5/5\n",
            "782/782 - 82s - 105ms/step - accuracy: 0.8257 - loss: 0.3937 - val_accuracy: 0.7562 - val_loss: 0.5207\n",
            "SimpleRNN Test accuracy: 0.7562 (time: 319.8s)\n",
            "\n",
            "=== Training GRU ===\n",
            "Epoch 1/5\n",
            "782/782 - 171s - 219ms/step - accuracy: 0.7670 - loss: 0.4741 - val_accuracy: 0.8414 - val_loss: 0.3597\n",
            "Epoch 2/5\n",
            "782/782 - 165s - 211ms/step - accuracy: 0.8960 - loss: 0.2614 - val_accuracy: 0.8516 - val_loss: 0.3495\n",
            "Epoch 3/5\n",
            "782/782 - 223s - 285ms/step - accuracy: 0.9408 - loss: 0.1584 - val_accuracy: 0.8369 - val_loss: 0.4179\n",
            "Epoch 4/5\n",
            "782/782 - 181s - 232ms/step - accuracy: 0.9688 - loss: 0.0882 - val_accuracy: 0.8282 - val_loss: 0.5172\n",
            "Epoch 5/5\n",
            "782/782 - 201s - 257ms/step - accuracy: 0.9834 - loss: 0.0495 - val_accuracy: 0.8241 - val_loss: 0.6456\n",
            "GRU Test accuracy: 0.8241 (time: 941.4s)\n",
            "\n",
            "=== Training LSTM ===\n",
            "Epoch 1/5\n",
            "782/782 - 190s - 244ms/step - accuracy: 0.7783 - loss: 0.4621 - val_accuracy: 0.8148 - val_loss: 0.4125\n",
            "Epoch 2/5\n",
            "782/782 - 202s - 258ms/step - accuracy: 0.8780 - loss: 0.2989 - val_accuracy: 0.8324 - val_loss: 0.3948\n",
            "Epoch 3/5\n",
            "782/782 - 186s - 238ms/step - accuracy: 0.9138 - loss: 0.2162 - val_accuracy: 0.8341 - val_loss: 0.4138\n",
            "Epoch 4/5\n",
            "782/782 - 186s - 238ms/step - accuracy: 0.9364 - loss: 0.1680 - val_accuracy: 0.8287 - val_loss: 0.4613\n",
            "Epoch 5/5\n",
            "782/782 - 199s - 255ms/step - accuracy: 0.9615 - loss: 0.1083 - val_accuracy: 0.8243 - val_loss: 0.5779\n",
            "LSTM Test accuracy: 0.8243 (time: 964.0s)\n",
            "\n",
            "=== Comparison ===\n",
            "    Model  Accuracy  Training Time (s)\n",
            "SimpleRNN   0.75624         319.763482\n",
            "      GRU   0.82408         941.371796\n",
            "     LSTM   0.82432         964.009812\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, SimpleRNN, GRU, LSTM\n",
        "from keras.datasets import imdb\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# -------------------\n",
        "# Hyperparameters\n",
        "# -------------------\n",
        "max_features = 20000   # number of words to consider as features\n",
        "maxlen = 80            # cut texts after this number of words\n",
        "batch_size = 32\n",
        "embedding_dim = 128\n",
        "epochs = 5             # you can increase for better results\n",
        "\n",
        "# -------------------\n",
        "# Load data\n",
        "# -------------------\n",
        "print(\"Loading IMDb dataset...\")\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "print(f\"Train shape: {x_train.shape}, Test shape: {x_test.shape}\")\n",
        "\n",
        "# -------------------\n",
        "# Helper function\n",
        "# -------------------\n",
        "def build_and_train(model_type=\"LSTM\", units=128):\n",
        "    print(f\"\\n=== Training {model_type} ===\")\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, embedding_dim, input_length=maxlen))\n",
        "\n",
        "    if model_type == \"SimpleRNN\":\n",
        "        model.add(SimpleRNN(units, dropout=0.2, recurrent_dropout=0.2))\n",
        "    elif model_type == \"GRU\":\n",
        "        model.add(GRU(units, dropout=0.2, recurrent_dropout=0.2))\n",
        "    elif model_type == \"LSTM\":\n",
        "        model.add(LSTM(units, dropout=0.2, recurrent_dropout=0.2))\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model type\")\n",
        "\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "                  optimizer=\"adam\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    start = time.time()\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        verbose=2)\n",
        "    end = time.time()\n",
        "\n",
        "    score, acc = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=0)\n",
        "    print(f\"{model_type} Test accuracy: {acc:.4f} (time: {end-start:.1f}s)\")\n",
        "    return model_type, acc, end-start\n",
        "\n",
        "# -------------------\n",
        "# Run all models\n",
        "# -------------------\n",
        "results = []\n",
        "for m in [\"SimpleRNN\", \"GRU\", \"LSTM\"]:\n",
        "    name, acc, runtime = build_and_train(m)\n",
        "    results.append((name, acc, runtime))\n",
        "\n",
        "# -------------------\n",
        "# Results table\n",
        "# -------------------\n",
        "df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Training Time (s)\"])\n",
        "print(\"\\n=== Comparison ===\")\n",
        "print(df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problema 2] (Tarea avanzada) Comparación entre múltiples conjuntos de datos Experimente con otros conjuntos de datos.\n",
        "# Documentación del conjunto de datos de Keras#\n",
        "# Un conjunto de datos de lenguaje natural fácil de usar en Keras es Reuters Newswire Topics Classification.#\n",
        "from keras.datasets import reuters\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, SimpleRNN, GRU, LSTM\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Use the same hyperparameters as IMDb\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "embedding_dim = 128\n",
        "epochs = 5\n",
        "\n",
        "# Load and preprocess Reuters dataset\n",
        "print(\"Loading Reuters dataset...\")\n",
        "(x_train_reuters, y_train_reuters), (x_test_reuters, y_test_reuters) = reuters.load_data(num_words=max_features)\n",
        "x_train_reuters = sequence.pad_sequences(x_train_reuters, maxlen=maxlen)\n",
        "x_test_reuters = sequence.pad_sequences(x_test_reuters, maxlen=maxlen)\n",
        "\n",
        "# Prepare labels for multi-class classification\n",
        "num_classes = max(y_train_reuters) + 1\n",
        "y_train_reuters = to_categorical(y_train_reuters, num_classes)\n",
        "y_test_reuters = to_categorical(y_test_reuters, num_classes)\n",
        "\n",
        "print(f\"Train shape: {x_train_reuters.shape}, Test shape: {x_test_reuters.shape}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Helper function for Reuters (multi-class classification)\n",
        "def build_and_train_reuters(x_train, y_train, x_test, y_test, model_type=\"LSTM\", units=128):\n",
        "    print(f\"\\n=== Training {model_type} on Reuters ===\")\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, embedding_dim, input_length=maxlen))\n",
        "\n",
        "    if model_type == \"SimpleRNN\":\n",
        "        model.add(SimpleRNN(units, dropout=0.2, recurrent_dropout=0.2))\n",
        "    elif model_type == \"GRU\":\n",
        "        model.add(GRU(units, dropout=0.2, recurrent_dropout=0.2))\n",
        "    elif model_type == \"LSTM\":\n",
        "        model.add(LSTM(units, dropout=0.2, recurrent_dropout=0.2))\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model type\")\n",
        "\n",
        "    # Multi-class classification requires softmax and categorical_crossentropy\n",
        "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(loss=\"categorical_crossentropy\",\n",
        "                  optimizer=\"adam\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    start = time.time()\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        verbose=2)\n",
        "    end = time.time()\n",
        "\n",
        "    score, acc = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=0)\n",
        "    print(f\"{model_type} Test accuracy: {acc:.4f} (time: {end-start:.1f}s)\")\n",
        "    return model_type, acc, end-start\n",
        "\n",
        "# Run all models on Reuters\n",
        "results_reuters = []\n",
        "for m in [\"SimpleRNN\", \"GRU\", \"LSTM\"]:\n",
        "    name, acc, runtime = build_and_train_reuters(x_train_reuters, y_train_reuters,\n",
        "                                                 x_test_reuters, y_test_reuters,\n",
        "                                                 model_type=m)\n",
        "    results_reuters.append((name, acc, runtime))\n",
        "\n",
        "# Results table\n",
        "df_reuters = pd.DataFrame(results_reuters, columns=[\"Model\", \"Accuracy\", \"Training Time (s)\"])\n",
        "print(\"\\n=== Reuters Results ===\")\n",
        "print(df_reuters.to_string(index=False))\n",
        "\n",
        "# Compare with IMDb results (if you want to show both)\n",
        "print(\"\\n=== Comparison: IMDb vs Reuters ===\")\n",
        "print(\"IMDb (Binary Classification):\")\n",
        "# Your IMDb results from before\n",
        "imdb_results = [\n",
        "    (\"SimpleRNN\", 0.7852, 48.9),\n",
        "    (\"GRU\", 0.8174, 1020.1),\n",
        "    (\"LSTM\", 0.8257, 1114.6)\n",
        "]\n",
        "df_imdb = pd.DataFrame(imdb_results, columns=[\"Model\", \"Accuracy\", \"Training Time (s)\"])\n",
        "print(df_imdb.to_string(index=False))\n",
        "\n",
        "print(\"\\nReuters (Multi-class Classification):\")\n",
        "print(df_reuters.to_string(index=False))"
      ],
      "metadata": {
        "id": "I4E8zzIxiHbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56bc276d-b0e1-4c70-9f74-c78ab681c4c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Reuters dataset...\n",
            "Train shape: (8982, 80), Test shape: (2246, 80)\n",
            "Number of classes: 46\n",
            "\n",
            "=== Training SimpleRNN on Reuters ===\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281/281 - 20s - 70ms/step - accuracy: 0.3274 - loss: 2.5650 - val_accuracy: 0.3718 - val_loss: 2.3119\n",
            "Epoch 2/5\n",
            "281/281 - 19s - 68ms/step - accuracy: 0.4047 - loss: 2.2569 - val_accuracy: 0.4029 - val_loss: 2.2105\n",
            "Epoch 3/5\n",
            "281/281 - 17s - 60ms/step - accuracy: 0.4575 - loss: 2.1019 - val_accuracy: 0.4185 - val_loss: 2.1996\n",
            "Epoch 4/5\n",
            "281/281 - 15s - 55ms/step - accuracy: 0.5007 - loss: 1.9349 - val_accuracy: 0.4252 - val_loss: 2.2197\n",
            "Epoch 5/5\n",
            "281/281 - 15s - 55ms/step - accuracy: 0.5515 - loss: 1.7769 - val_accuracy: 0.4332 - val_loss: 2.2430\n",
            "SimpleRNN Test accuracy: 0.4332 (time: 91.5s)\n",
            "\n",
            "=== Training GRU on Reuters ===\n",
            "Epoch 1/5\n",
            "281/281 - 59s - 210ms/step - accuracy: 0.4501 - loss: 2.0810 - val_accuracy: 0.5289 - val_loss: 1.8512\n",
            "Epoch 2/5\n",
            "281/281 - 80s - 286ms/step - accuracy: 0.5610 - loss: 1.6783 - val_accuracy: 0.5579 - val_loss: 1.7196\n",
            "Epoch 3/5\n",
            "281/281 - 83s - 296ms/step - accuracy: 0.6151 - loss: 1.5158 - val_accuracy: 0.5980 - val_loss: 1.5921\n",
            "Epoch 4/5\n",
            "281/281 - 54s - 194ms/step - accuracy: 0.6556 - loss: 1.3210 - val_accuracy: 0.6113 - val_loss: 1.5215\n",
            "Epoch 5/5\n",
            "281/281 - 85s - 301ms/step - accuracy: 0.7057 - loss: 1.1223 - val_accuracy: 0.6331 - val_loss: 1.4792\n",
            "GRU Test accuracy: 0.6331 (time: 361.6s)\n",
            "\n",
            "=== Training LSTM on Reuters ===\n",
            "Epoch 1/5\n",
            "281/281 - 64s - 228ms/step - accuracy: 0.4385 - loss: 2.1678 - val_accuracy: 0.5329 - val_loss: 1.8038\n",
            "Epoch 2/5\n",
            "281/281 - 62s - 219ms/step - accuracy: 0.5435 - loss: 1.7174 - val_accuracy: 0.5646 - val_loss: 1.7016\n",
            "Epoch 3/5\n",
            "281/281 - 59s - 211ms/step - accuracy: 0.6122 - loss: 1.4726 - val_accuracy: 0.6082 - val_loss: 1.5203\n",
            "Epoch 4/5\n",
            "281/281 - 82s - 292ms/step - accuracy: 0.6802 - loss: 1.2066 - val_accuracy: 0.6465 - val_loss: 1.4570\n",
            "Epoch 5/5\n",
            "281/281 - 60s - 215ms/step - accuracy: 0.7355 - loss: 1.0055 - val_accuracy: 0.6567 - val_loss: 1.4152\n",
            "LSTM Test accuracy: 0.6567 (time: 327.9s)\n",
            "\n",
            "=== Reuters Results ===\n",
            "    Model  Accuracy  Training Time (s)\n",
            "SimpleRNN  0.433215          91.487284\n",
            "      GRU  0.633126         361.575578\n",
            "     LSTM  0.656723         327.894824\n",
            "\n",
            "=== Comparison: IMDb vs Reuters ===\n",
            "IMDb (Binary Classification):\n",
            "    Model  Accuracy  Training Time (s)\n",
            "SimpleRNN    0.7852               48.9\n",
            "      GRU    0.8174             1020.1\n",
            "     LSTM    0.8257             1114.6\n",
            "\n",
            "Reuters (Multi-class Classification):\n",
            "    Model  Accuracy  Training Time (s)\n",
            "SimpleRNN  0.433215          91.487284\n",
            "      GRU  0.633126         361.575578\n",
            "     LSTM  0.656723         327.894824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problema 3] Explicación de otras clases Hay otras clases relacionadas en la documentación.\n",
        "\n",
        "Explíquelas. Algunas de estas clases rara vez se usan en la práctica.\n",
        "\n",
        "Enfermera registrada SimpleRNNCell GRUCell Celda LSTMCell Células RNN apiladas CuDNNGRU CuDNNNLSTM prueba#"
      ],
      "metadata": {
        "id": "2bvx8t1eET-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import RNN, SimpleRNNCell, GRUCell, LSTMCell, StackedRNNCells, Dense, Embedding\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Example 1: Using SimpleRNNCell inside RNN\n",
        "model1 = Sequential([\n",
        "    Embedding(max_features, 128),\n",
        "    RNN(SimpleRNNCell(32)),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Example 2: Using GRUCell\n",
        "model2 = Sequential([\n",
        "    Embedding(max_features, 128),\n",
        "    RNN(GRUCell(32)),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Example 3: Using LSTMCell\n",
        "model3 = Sequential([\n",
        "    Embedding(max_features, 128),\n",
        "    RNN(LSTMCell(32)),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Example 4: Stacked cells (2 LSTM layers in one RNN)\n",
        "stacked_cells = StackedRNNCells([LSTMCell(32), LSTMCell(32)])\n",
        "model4 = Sequential([\n",
        "    Embedding(max_features, 128),\n",
        "    RNN(stacked_cells),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model1\n",
        "model2\n",
        "model3\n",
        "model4"
      ],
      "metadata": {
        "id": "JaPecx1kihZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e765f9b6-185e-47e1-a4ed-84ce56287085"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Sequential name=sequential_25, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IneZUlw0iuBm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}